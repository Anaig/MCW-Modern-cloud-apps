![](images/HeaderPic.png "Microsoft Cloud Workshops")

# Modern cloud apps

## Whiteboard design session trainer guide

## March 2018

Information in this document, including URL and other Internet Web site references, is subject to change without notice. Unless otherwise noted, the example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and events depicted herein are fictitious, and no association with any real company, organization, product, domain name, e-mail address, logo, person, place or event is intended or should be inferred. Complying with all applicable copyright laws is the responsibility of the user. Without limiting the rights under copyright, no part of this document may be reproduced, stored in or introduced into a retrieval system, or transmitted in any form or by any means (electronic, mechanical, photocopying, recording, or otherwise), or for any purpose, without the express written permission of Microsoft Corporation.

Microsoft may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter in this document. Except as expressly provided in any written license agreement from Microsoft, the furnishing of this document does not give you any license to these patents, trademarks, copyrights, or other intellectual property.

The names of manufacturers, products, or URLs are provided for informational purposes only and Microsoft makes no representations and warranties, either expressed, implied, or statutory, regarding these manufacturers or the use of the products with any Microsoft technologies. The inclusion of a manufacturer or product does not imply endorsement of Microsoft of the manufacturer or product. Links may be provided to third party sites. Such sites are not under the control of Microsoft and Microsoft is not responsible for the contents of any linked site or any link contained in a linked site, or any changes or updates to such sites. Microsoft is not responsible for webcasting or any other form of transmission received from any linked site. Microsoft is providing these links to you only as a convenience, and the inclusion of any link does not imply endorsement of Microsoft of the site or the products contained therein.
Â© 2018 Microsoft Corporation. All rights reserved.

Microsoft and the trademarks listed at https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx are trademarks of the Microsoft group of companies. All other trademarks are property of their respective owners.

## Contents 

<!-- TOC -->

- [Modern cloud apps](#modern-cloud-apps)
    - [Whiteboard design session trainer guide](#whiteboard-design-session-trainer-guide)
    - [March 2018](#march-2018)
    - [Contents](#contents)
    - [Trainer information](#trainer-information)
    - [Role of the trainer](#role-of-the-trainer)
        - [Whiteboard design session flow](#whiteboard-design-session-flow)
        - [Before the whiteboard design session: How to prepare](#before-the-whiteboard-design-session--how-to-prepare)
        - [During the whiteboard design session: Tips for an effective whiteboard design session](#during-the-whiteboard-design-session--tips-for-an-effective-whiteboard-design-session)
- [Modern cloud apps whiteboard design session student guide](#modern-cloud-apps-whiteboard-design-session-student-guide)
    - [Abstract and learning objectives](#abstract-and-learning-objectives)
    - [Step 1: Review the customer case study](#step-1--review-the-customer-case-study)
        - [Facilitator/subject matter expert (SME) presentation of customer case study](#facilitator-subject-matter-expert-sme-presentation-of-customer-case-study)
        - [Customer situation](#customer-situation)
        - [Customer needs](#customer-needs)
        - [Customer objections](#customer-objections)
        - [Infographic for common scenarios](#infographic-for-common-scenarios)
    - [Step 2: Design a proof of concept solution](#step-2--design-a-proof-of-concept-solution)
    - [Step 3: Present the solution](#step-3--present-the-solution)
    - [Wrap-up](#wrap-up)
    - [Additional references](#additional-references)
- [Modern cloud apps whiteboard design session trainer guide](#modern-cloud-apps-whiteboard-design-session-trainer-guide)
    - [Step 1: Review the customer case study](#step-1--review-the-customer-case-study)
    - [Step 2: Design a proof of concept solution](#step-2--design-a-proof-of-concept-solution)
    - [Step 3: Present the solution](#step-3--present-the-solution)
    - [Wrap-up](#wrap-up)
    - [Preferred target audience](#preferred-target-audience)
    - [Preferred solution](#preferred-solution)
    - [Checklist of preferred objection handling](#checklist-of-preferred-objection-handling)
    - [Customer quote (to be read back to the attendees at the end)](#customer-quote-to-be-read-back-to-the-attendees-at-the-end)

<!-- /TOC -->

## Trainer information

Thank you for taking time to support the whiteboard design sessions as a trainer!

## Role of the trainer

An amazing trainer:

-   Creates a safe environment in which learning can take place.

-   Stimulates the participant's thinking.

-   Involves the participant in the learning process.

-   Manages the learning process (on time, on topic, and adjusting to benefit participants).

-   Ensures individual participant accountability.

-   Ties it all together for the participant.

-   Provides insight and experience to the learning process.

-   Effectively leads the whiteboard design session discussion.

-   Monitors quality and appropriateness of participant deliverables.

-   Effectively leads the feedback process.

### Whiteboard design session flow 

Each whiteboard design session uses the following flow:

**Step 1: Review the customer case study (15 minutes)**

Outcome: Analyze your customer's needs

-   Customer's background, situation, needs and technical requirements

-   Current customer infrastructure and architecture

-   Potential issues, objectives and blockers

**Step 2: Design a proof of concept solution (60 minutes)**

Outcome: Prepare to present a solution for your target customer audience

-   Determine your target customer audience

-   Determine customer's business needs to address your solution

-   Design and diagram your solution

-   Prepare to present your solution

**Step 3: Present the solution (30 minutes)**

Outcome: Present solution to your customer

-   Present solution

-   Respond to customer objections

-   Receive feedback

**Wrap-up (15 minutes)**

-   Review preferred solution

### Before the whiteboard design session: How to prepare

Before conducting your first whiteboard design session:

-   Read the Student guide (including the case study) and Trainer guide

-   Become familiar with all key points and activities.

-   Plan the point you want to stress, which questions you want to drive, transitions, and be ready to answer questions.

-   Prior to the whiteboard design session, discuss the case study to pick up more ideas.

-   Make notes for later.

### During the whiteboard design session: Tips for an effective whiteboard design session

**Refer to the Trainer guide** to stay on track and observe the timings.

**Do not expect to memorize every detail** of the whiteboard design session.

When participants are doing activities, you can **look ahead to refresh your memory**.

-   **Adjust activity and whiteboard design session pace** as needed to allow time for presenting, feedback, and sharing.

-   **Add examples, points, and stories** from your own experience. Think about stories you can share that help you make your points clearly and effectively.

-   **Consider creating a "parking lot"** to record issues or questions raised that are outside the scope of the whiteboard design session or can be answered later. Decide how you will address these issues, so you can acknowledge them without being derailed by them.

***Have fun**! Encourage participants to have fun and share!*

**Involve your participants.** Talk and share your knowledge but always involve your participants, even while you are the one speaking.

**Ask questions** and get them to share to fully involve your group in the learning process.

**Ask first**, whenever possible. Before launching into a topic, learn your audience's opinions about it and experiences with it. Asking first enables you to assess their level of knowledge and experience, and leaves them more open to what you are presenting.

**Wait for responses**. If you ask a question such as, "What's your experience with (fill in the blank)?" then wait. Do not be afraid of a little silence. If you leap into the silence, your participants will feel you are not serious about involving them and will become passive. Give participants a chance to think, and if no one answers, patiently ask again. You will usually get a response.

#  Modern cloud apps whiteboard design session student guide

## Abstract and learning objectives 

In this Microsoft Cloud Workshop, attendees will implement an end-to-end solution for e-commerce that is based on Azure App Services, Azure Active Directory, and Visual Studio Online. Attendees will ensure the solution is PCI-compliant, and appropriate security measures are put into place for both on-premises and public access scenarios.

Attendees will be better able to deploy and configure Azure Web Apps and associated services. In addition,

-   Configure Web Apps for authentication with Azure AD

-   Instrument and load-test the application with App Insights

-   Automate backend services using Logic Apps

## Step 1: Review the customer case study 

**Outcome**

Analyze your customer's needs.

### Facilitator/subject matter expert (SME) presentation of customer case study 

Timeframe: 15 minutes

Directions: With all participants in the session, the facilitator/SME presents an overview of the customer case study along with technical tips.

1.  Meet your table participants and trainer.

2.  Read all of the directions for Steps 1--3 in the Student guide.

3.  As a table team, review the following customer case study.
 
### Customer situation

The Contoso Sports League Association (CSLA) is one of the largest sports franchises. They have over 100 championships in their history and a huge, passionate fan base. They run a highly successful e-commerce website that sells merchandise to their legions of sports fans. The website is built using ASP.NET and currently hosted in a co-location.

They accept payment by credit card and owing to their high annual volume (in the tens of millions, processing about 50K per day) of transactions, need to ensure that they are Payment Card Industry Data Security Standards (PCI DSS) Level 1 compliant. Their website hosts the shopping cart and checkout process, but they defer the credit card authorization and capture responsibilities of the credit card processing to a third-party payment gateway. This payment gateway provides a web application programming interface (API) that is invoked over Transport Layer Security (TLS) from Contoso server-side logic. The call includes the credit card holder data (name, number, and so on) and returns a status indicating a success or failure in authorizing and capturing payment against the credit card. It is called after the customer clicks checkout, as a part of processing the order. They currently store their customer and profile data in SQL Server 2014.

In addition to the public facing e-commerce website, they have a backend website that supports their call center. Call center employees use this admin website to view customer orders. Customers can call in to the call center to place orders and pay for orders with their credit cards by phone.

CSLA manages the order fulfillment process. When an order arrives, they store the order details in their SQL database, and send a message for each order to their inventory management system running the warehouse. CSLA experiences a roughly 12-hour window that spans east to west coast business hours, during which they get most of their orders. The warehouse receives the message (which simply contains the order ID from the database), pulls up the order details identified in the message (by a lookup against the database), and then for each item in the order queues up a separate process to locate the item in inventory or place an order for it with their supplier. Once this initial status for each item in the order is collected, the inventory status is updated in the database and a confirmation email is sent to the customer indicating the estimated delivery date of their completed order (and if any items are in backorder). This inventory lookup rarely takes more than a few hours and never more than a day.

They have reached a point where managing their server infrastructure is becoming a real challenge and are interested in understanding more about platform as a service (PaaS) solutions that could help them focus their efforts more on the core business value rather than infrastructure. They have observed that Azure has received PCI compliance certification, and are interested in moving their solution to Azure. "We're finding that with every upgrade, we're spending more and more engineering time on infrastructure and less on the experience that matters most to our fan base," says Francisco Martinez, Chief Executive Officer (CEO) of Contoso Sports League Association, "we need to rebalance those efforts."

One example is in how they manage the usernames and passwords for call center operators and support staff, as applied to the call center admin website. Today they have a homegrown solution that stores usernames and passwords in the same database used for storing merchandise information. They have experimented with other third-party solutions in the past, and their employees found it jarring to see another company's logo displayed when logging into their own call center website. In creating their identity solution, they want to ensure they can brand the login screens with their own logo. Additionally, Contoso is concerned about hackers from foreign countries/regions gaining access to the administrator site. Before they choose an identity solution, they would like to see how it indicates such attempts.

There is one architectural enhancement Contoso would like to make in the transition to a PaaS solution. When a visitor loads the home page, it gets the list of featured products on offer (consisting of the product image, title, and URL) from the Offers service. The home page does it using a client-side GET request against an ASP.NET Web API 2 service that is executed as the page loads in the browser. Contoso anticipates growing the functionality of this service and would like to scale it independently of the website.

Contoso is also looking to augment their data analytics story by introducing a data warehouse to enable them to analyze their historical data over time, particularly as their number of transactions soars in the cloud. They would like to plan for a solution that moves the data from their OLTP database into their data warehouse on a nightly basis, ideally with the minimum amount of infrastructure or development effort. 

### Customer needs 

1.  Maintain existing PCI compliance.

2.  Ensure data privacy and protection across all aspects of the system, in transit and at rest.

3.  Make architectural decisions that help to minimize engineering around infrastructure in favor of those that deliver core business value.

4.  Ensure that they retain their core functionality, even if the way it is accomplished under the covers might change.

5.  Provide a better solution for the management of usernames and passwords.

6.  Provide a regional database failover plan that will enable the customer to initiate the failover to another region, allowing their various web applications and other hosted services to roll over to a synchronized database at minimal cost.

7.  A data warehouse for analyzing their transaction history.

### Customer objections 

1.  It is not clear to us from the Azure Trust Center just how Azure helps our solution become PCI compliant.

2.  Can we provide a solution that scales to meet our public demand, but is also secure for use by our call center and warehouse?

3.  Our PCI compliance requires us to have a quarterly audit and to conduct occasional penetration tests. Is it supported by Azure?

4.  Can we audit the Azure data center?

5.  In the past, we have relied on SOASTA CloudTest to design and execute our web load tests at scale. In moving to Azure, are we still take advantage of CloudTest?

6.  Our previous infrastructure did not have great performance monitoring of our websites. What options would you recommend we investigate that would work with our web apps in Azure?

1.  We have heard that Azure's data warehouse can be paused? Does that mean we have to store all our data in Azure Storage first before we can pause the instances and risk losing our data? 

### Infographic for common scenarios

![This diagram is of a Common scenario for an E-Commerce Website. The diagram begins with an end user, includes a services tier, internet tier, and data tier, and ends at an Enterprise. The diagram also includes Microsoft Azure, and Azure Virtual Network.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image2.png "Common scenario for an E-Commerce Website")

## Step 2: Design a proof of concept solution

**Outcome**

Design a solution and prepare to present a solution to the target customer audience in a 15-minute chalk-talk format.

Timeframe: 60 minutes

**Business needs**

Directions: With all participants at your table, answer the following questions and list the answers on a flip chart.

1.  Who should you present this solution to? Who is your target customer audience? Who are the decision makers?

2.  What customer business needs do you need to address with your solution?

**Design**

Directions: With all participants at your table, respond to the following questions on a flip chart.

*High-level architecture*

1.  Without getting into the details, (the following sections will address the details), diagram your initial vision for handling the top-level requirements for the e-commerce website, call center website, and inventory lookup process. You will refine this diagram as you proceed.

*Order fulfillment*

1.  How would you recommend CSLA manage the inventory lookup queues? How would you help CSLA decide between Azure Queues and Service Bus? Be sure to consider details implied by CSLA's requirements such as volume, message lifetime, and sizing. Explain the details of any computations you make.

*Notifications*

1.  How would you recommend CSLA manage notifying customers as their order in the CSLA orders database is processed? Are there specific Azure services that can be used? Include details on how this would be implemented and integrated into the proposed solution for CSLA.

*Offers service*

1.  Would you propose Contoso use the Azure App Service API app to meet their requirements for the Offers service?

2.  If so, what specific configurations would you need to make to support your proposed topology?

3.  Specifically, how would you implement the changes and configurations required to allow for inter-app communication between the e-commerce application and the Offers service?

*Geo-resiliency*

1.  How would you implement high availability for the orders database to guard against regional data center outages? Be specific on how you would configure SQL Database and Azure Storage.

2.  What mechanisms would you provide to the customer to initiate a failover in the event of an outage, ensuring their web applications and associated Azure services change over to a secondary region?

3.  How long would a failover take and how much data could be lost, in terms of time?

*Access control*

1.  With respect to managing access to the call center website, explain how you would recommend Contoso implement a solution that meets their requirements. Be specific about both the implementation and the process you would use to gain Contoso's acceptance of the proposed solution.

*Enabling PCI compliance*

1.  Keeping only the e-commerce website and handling of cardholder data in scope for PCI, consider the following in your design:

    a.  Are web apps deployed in Azure App Service Environments an option?

    -   Explain how using Azure App Service Environments could address the PCI requirements.

    -   Keeping in mind the best choice for securing inbound and outbound traffic for an App Service Environment, detail all inbound and outbound traffic for this solution that allows it to be PCI compliant and allows it to operate within Azure. It should include traffic into and out of the solution, outbound for the e-commerce website, and any other traffic between the apps within the solution.

    -   Make sure to describe in detail the network topology you are using.

    -   For any inbound and outbound application communications you are securing, please detail the specific mechanisms you will use to do so.

    -   If your approach includes configuration scripts, please provide an example of the scripts.

    -   Would you recommend they use Azure virtual machines? Why or why not?

*Data warehouse*

1.  *How would you recommend Contoso implement their data warehouse?*

2.  *How would Contoso schedule nightly data transfers from their OLTP database to their data warehouse?*

*Access control*

1.  How would you recommend Contoso implement their data warehouse?

2.  How would Contoso schedule nightly data transfers from their OLTP database to their data warehouse?

**Prepare**

Directions: With all participants at your table:

1.  Identify any customer needs that are not addressed with the proposed solution.

2.  Identify the benefits of your solution.

3.  Determine how you will respond to the customer's objections.

Prepare a 15-minute chalk-talk style presentation to the customer.

## Step 3: Present the solution

**Outcome**

Present a solution to the target customer audience in a 15-minute chalk-talk format.

**Presentation**

Timeframe: 30 minutes

**Directions**

1.  Pair with another table.

2.  One table is the Microsoft team and the other table is the customer.

3.  The Microsoft team presents their proposed solution to the customer.

4.  The customer makes one of the objections from the list of objections.

5.  The Microsoft team responds to the objection.

6.  The customer team gives feedback to the Microsoft team.

7.  Tables switch roles and repeat Steps 2--6.

##  Wrap-up 

Timeframe: 15 minutes

-   Tables reconvene with the larger group to hear a SME share the preferred solution for the case study.

##  Additional references

|    |            |
|----------|:-------------:|
| **Description** | **Links** |
| Compliance Commitments | <http://azure.microsoft.com/en-us/support/trust-center/services/> |
| Azure App Services | <https://azure.microsoft.com/en-us/documentation/articles/app-service-value-prop-what-is/> |
| Azure Service Environment | <https://azure.microsoft.com/en-us/documentation/articles/app-service-app-service-environment-intro/> |
| Azure Trust Center | <http://azure.microsoft.com/en-us/support/trust-center/> |
| Azure PCI Attestation of Compliance | <http://download.microsoft.com/download/7/1/E/71E02A19-D1A4-448F-8CEA-D6A19398ABDA/Azure%20PCI%20AOC%20Feb%202015.pdf> |
| PCI DSS v3.0 | <https://www.pcisecuritystandards.org/documents/PCI_DSS_v3.pdf> |
| Azure Data Factory | <https://azure.microsoft.com/en-us/documentation/articles/data-factory-data-movement-activities/#data-factory-copy-wizard/> |
| Azure SQL Database | <https://docs.microsoft.com/en-us/azure/sql-database/sql-database-geo-replication-overview/> |
|

# Modern cloud apps whiteboard design session trainer guide

## Step 1: Review the customer case study

-   Check in with your table participants to introduce yourself as the trainer.

-   Ask, "What questions do you have about the customer case study?"

-   Briefly review the steps and timeframes of the whiteboard design session.

-   Ready, set, go! Let the table participants begin.

## Step 2: Design a proof of concept solution

-   Check in with your tables to ensure that they are transitioning from step to step on time.

-   Provide some feedback on their responses to the business needs and design.

    -   Try asking questions first that will lead the participants to discover the answers on their own.

-   Provide feedback for their responses to the customer's objections.

    -   Try asking questions first that will lead the participants to discover the answers on their own.

## Step 3: Present the solution

-   Determine which table will be paired with your table before Step 3 begins.

-   For the first round, assign one table as the Microsoft team and the other table as the customer.

-   Have the Microsoft team present their solution to the customer team.

    -   Have the customer team provide one objection for the Microsoft team to respond to.

    -   The presentation and objections should be no longer than 10 minutes.

-   Have participants on the customer team give feedback to the Microsoft team.

    -   The feedback should be no longer than 5 minutes.

    -   If needed, the trainer may also provide feedback.

## Wrap-up

-   Have the table participants reconvene with the larger session group to hear a SME share the following preferred solution.

##  Preferred target audience

Francisco Martinez, CEO of Contoso Sports League Association

The primary audience is the business decision makers and technology decision makers. Usually we talk to the infrastructure managers who report to the chief information offer (CIO), or to application sponsors (like a vice president \[VP\] line of business \[LOB\], or chief marketing officer \[CMO\]), or to those that represent the business unit IT or developers that report to application sponsors.

## Preferred solution

*High-level architecture*

1.  *Without getting into the details, (the following sections will address the details), diagram your initial vision for handling the top-level requirements for the e-commerce website, call center website, and inventory lookup process. You will refine this diagram as you proceed.*

    The Contoso Sports League Association (CSLA) was motivated to move its solution to Azure. After analyzing their requirements across the e-commerce, inventory, and customer support apps, they built their solution from the following high-level designs.

    They decided on a solution that at a high level appears as follows:

    ![Diagram of the preferred solution. From a high-level, web apps hosting the e-commerce and call center websites access APIs hosted in API Apps, all hosted within an App Service Environment to enable secure communication. Access to call center website available through VPN connection only.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image3.png "Preferred solution diagram")

    From a high-level, they have Web Apps hosting the e-commerce and call center websites, API Apps hosting web services and Logic Apps hosting integration with SMS. These can be hosted within App Service Environment that enables them to take advantage of Network Security Groups to lock down inbound and outbound communication to the App Services it hosts. When customers visit the website, they are presented orders whose data comes from the Offers Service REST API hosted within an API App. Orders come in from customers via the publicly accessible endpoint of the e-commerce website. The credit card is validated as a part of the checkout process by making a call to a third-party payment gateway. Once authorized and payment is captured, the order data is stored in the orders database on SQL DB and the inventory lookup message is sent to the Inventory Lookup queue. An azure Worker Role or Azure Function hosts the process for creating the PDF receipts for customer purchases. Customers are notified via SMS as their order is processed. This process involves a process running in a Logic App that integrates the SQL DB with a third-party solution for sending SMS text messages.

    Inventory lookup requests are queued from the e-commerce website to the queue in Azure Storage queues. The on-premises inventory app reads from this queue to kick off its internal lookup processes and writes the status back to the orders database.

    Call center operators access the call center website which, owing to the NSGs configured, is only available across the virtual private network (VPN) connection.

*NOTE: The preferred solution is only one of many possible, viable approaches.*

*Order fulfillment*

1.  *How would you recommend CSLA manage the inventory lookup queues? How would you help CSLA decide between Azure Queues and Service Bus? Be sure to consider details implied by CSLA's requirements such a volume, message lifetime, and sizing. Explain the details of any computations you make.*

    Given that CSLA did not provide specific requirements that imply a need for the more advanced queuing features that Service Bus offers (such as topics, larger message sizes, longer message lifetime, and so on), CSLA should consider using Azure Queues because it meets their requirements and is the most cost effective.

    Their volume is fairly low---at 50K transactions per day it translates to 50K messages per day. Their actual load per unit of time depends on their actual peak order times that is implied to be akin to 9 a.m.--9 p.m. EST. Assuming a fairly consistent load during business hours, that equates to about 4,000 messages per hour, which is well below what Azure Queues can support (2,000 messages per second or approximately 120,000 messages per hour for messages sized below 1 kilobyte \[KB\]).

    The case study states that rarely does an inventory lookup message take longer than a few hours and never more than a day. It means that they will never encounter the 7-day lifetime limit required by messages in Azure Queues.

    As for the individual message size, since it is just the order ID from the database, it is unlikely to be a field larger than 64 KB (the maximum message size supported by Azure Queues), or even 1 KB (the size at which Azure Queues can handle 2,000 messages per second).

*Notifications*

1.  *How would you recommend CSLA manage notifying customers as their order in the CSLA orders database is processed? Are there specific Azure services that can be used? Include details on how this would be implemented and integrated into the proposed solution for CSLA.*

    Contoso can implement a logic app to notify customers of their order status.

    The logic app would include a frequency trigger to execute a stored procedure at an interval that will identify orders that should receive SMS notifications and update them as they are processed.

    A Twilio connector could act as the action to perform that sends the SMS message when the frequency trigger executes the stored procedure. CSLA would sign up for a free Twilio trial to get an API key. Then they would provision a Twilio connector within the logic app, and add the credentials. Then CSLA would select a Send Message action using data provided in the result set from the stored procedure, specifically the customer's phone number and their first name to include in the message, "Hello Satya, your order has shipped!"\
Note: It currently involves extending the Logic App code for the Twilio connector.

*Offers service*

1.  *Would you propose Contoso use the Azure App Service API app to meet their requirements for the Offers service?*

    Contoso could meet their requirement of scaling the Offers API independently from the main website by separating it out from the website project into its own Web API project and deploying that project to an Azure App Service API App.

2.  *If so, what specific configurations would you need to make to support your proposed topology? Specifically, how would you implement the changes and configurations required to allow for inter-app communication between the e-commerce application and the Offers service?*

    In order for the home page to be able to successfully retrieve the data from the now separate Web API (for example, it is located in another origin), cross origin resource sharing (CORS) would need to be configured.

    The API app would need to be enabled for CORS, and the domains used to access the website in the list of allowed origins would need to be listed.

    Second, the Web API code would need to be updated to include the System.Web.Http.Cors package, where CORS would need to be enabled in the WebApiConfig.cs file, and the EnableCors attribute would need to be applied to the controllers or actions of the Offers service allowing the aforementioned origins and allow the GET method.

    It may also be worth clarifying plans with Contoso---that if Contoso chooses to open access of the Offers service for integration by partners they should also consider implementing API management in front of their API App hosted Web API. This would enable them to lock down access by requiring a key, apply policy (such as rate limiting requests), and monitor usage by API customers.

*Geo-resiliency*

1.  *How would you implement high availability for the orders database to guard against regional data center outages? Be specific on how you would configure SQL Database and Azure Storage.*

    Azure SQL Database auto-failover groups (in-preview) is a SQL Database feature designed to automatically manage geo-replication relationship, connectivity, and failover at scale. With it, the customers gain the ability to automatically recover multiple related databases in the secondary region after catastrophic regional failures or other unplanned events that result in full or partial loss of the SQL Database service's availability in the primary region. Additionally, they can use the readable secondary databases to offload read-only workloads. Because auto-failover groups involve multiple databases, they must be configured on the primary server. Both primary and secondary servers must be in the same subscription. Auto-failover groups support replication of all databases in the group to only one secondary server in a different region. Active geo-replication, without auto-failover groups, allows up to four secondaries in any region.

    Provision the Azure Storage Account with RA-GRS redundancy with a primary and secondary geographic location matching those of the SQL databases, so that in the event of an outage all backup regions have copies of the data. It may affect your choice of SQL database secondary regions because the primary/secondary regions pairs for storage are predefined and not user selectable (e.g., West US primary will use East US as secondary). The replication between the primary storage account region and secondary storage account region is asynchronous to it does not impact the latency of requests made against the primary region (albeit some data loss might be possible if it has not replicated to the secondary region in the event of a disaster).

    Finally, deploy copies of the App Services to the backup regions (you will have to consider a process of how you update these instances when the primary region gets updates). These can initially be deployed to resources with minimal scale out instance sizes, and increased when failover event occurs.

2.  What process would you recommend to the customer to failover in the event of an outage, ensuring their web applications and associated Azure services change over to a secondary region?

    When using auto-failover groups (in-preview) to manage database recovery and any outage that impacts one or several of the databases in the group results in automatic failover. You can configure the auto-failover policy that best meets your application needs, or you can opt out and use manual activation. Whether you use manual or automatic failover activation, failover switches all secondary databases in the group to primary. After the database failover is completed, the DNS record is automatically updated to redirect the end-points to the new region.

    Understand that for Azure Storage, the geo-failover process is controlled by Azure. in the event of a major disaster that affects the primary location, Azure will first try to restore the data in the primary location. Failing that, affected customers will be notified via their subscription contact information. As part of the failover, the customer's "account.\<service\>.core.windows.net" DNS entry would be updated to point from the primary location to the secondary location. In other words, the connection information to Azure Storage does not need to be changed in the application configuration.

1.  How long would a failover take and how much data could be lost, in terms of time?

    The amount of time a failover takes is the Recovery Time Objective (RTO) and the amount of data loss that might transpire due to any replication latency is the Recovery Point Objective (RPO).

    For SQL Database on the Premium Tier, the RTO is less than 30 seconds and the RPO is less than 5 seconds.

    For Azure Storage, the RTO is about 24 hours and the RPO is typically less than 15 minutes (though this has no explicit SLA). Given the potentially long RTO and RPO for Azure Storage, Contoso might consider using RA-GRS storage and when a failover happens use the RA-GRS for read and a separate storage account for the writing of new files.

*Access control*

1.  *With respect to managing access to the call center website, explain how you would recommend Contoso implement a solution that meets their requirements. Be specific about both the implementation and the process you would use to gain Contoso's acceptance of the proposed solution.*

    Contoso could capitalize on Azure Active Directory to manage the user accounts for the call center staff. They would need to provision an Azure Active Directory tenant in the Premium Tier to provide the branding. Once they have the tenant, they can create login screen branding by using the management portal.

    ![Use the Azure Active Directory Status section to configure custom branding for your company.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image4.png "Status section")

    From there they specify images for the banner logo, a tile logo, and large illustration, and provide some custom text.

    ![In the Configure company branding blade, select a file to use as the large image that displays to the left of the custom login form.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image5.png "Configure company branding blade")

    It would result in something like the following for Contoso:

    ![Screenshot of the Contoso sign-in webpage.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image6.png "Contoso sign-in webpage")

    With respect to addressing Contoso's concerns over foreign hackers, Azure Active Directory can help by identifying logins from multiple geographic locations by using the report "Sign ins from multiple geographies." To demonstrate the function of it to Contoso, one approach to accomplish a login from a foreign IP is to spin up a virtual machine in Azure in a foreign geography, remote desktop into it, open the browser, and navigate to the Contoso admin site and log in. Then log in from a local machine at the same time. Within an hour or two the suspicious login would be listed in the report.

    Provided that the call center administrator website is deployed to a web app and that currently anyone listed as a user in Azure Active Directory is a user who should have access to the call center website (since the case study does not stipulate any other more granular requirements), the setup for integrating Azure Active Directory access control requires no code on the part of Contoso, just configuration. This configuration is accomplished using the Azure portal (at https://portal.azure.com), navigating to the web app, and on the Settings blade selecting Authentication/Authorization. Then in the Authentication/Authorization blade, choose Login with Azure Active Directory, and then configure the Azure Active Directory authentication provider to create a new application in AAD or to use an existing application.

    ![On the Azure Portal, Authentication/Authorization blade, App Service Authorization is set to On, Users must Log in with Azure Active Directory when their request is not authenticated, and Authentication Provider is Azure Active Directory.](images/Whiteboarddesignsessiontrainerguide-Moderncloudappsimages/media/image7.png "Azure Portal, Authentication/Authorization blade")

    Once applied, any access to the call center admin website will automatically be redirected to first log in through Azure Active Directory, and users would need to be created in Azure Active Directory in order to acquire access.

*Enabling PCI compliance*

1.  Keeping only the e-commerce website and handling of cardholder data in scope for PCI, consider the following in your design:

    *Are web apps deployed in Azure App Service Environments an option?*

    a.  *Explain how using Azure App Service Environments could address the PCI requirements.*

    b.  *Keeping in mind the best choice for securing inbound and outbound traffic for an App Service Environment, detail all inbound and outbound traffic for this solution that allows it to be PCI compliant and allows it to operate within Azure. It should include traffic into and out of the solution, outbound for the e-commerce website, and any other traffic between the apps within the solution.*

    c.  *Make sure to describe in detail the network topology you are using. *

    d.  *For any inbound and outbound application communications you are securing, please detail the specific mechanisms you will use to do so.*

    e.  *If your approach includes configuration scripts, please provide an example of the scripts.*

    While web apps are certified as PCI compliant, they are not immediately PCI compliant when used by the customer. The PCI requirements 1.2.1, 1.3.3, and 1.3.5 require restricting outbound access to only that which is necessary for the cardholder environment. In the case of CSLA, it means that the only outbound communication allowed should be to Azure (for monitoring) and to the payment gateway. Web apps in the Standard Tier have no mechanism for restricting the outbound traffic. However, by provisioning a web app in the Premium Tier Application Service Environment (ASE), outbound security can be controlled using National Security Groups (NSGs).

    If restricting the *inbound* communication (for example limiting by IP, port, protocol) to a web app from the Internet, then you need to:

    -   Provision ASE, along with an Azure Virtual Network.

    -   Provision the app hosting plan from the ASE pool of resources.

    -   Provision a web app in that App Service plan (no need to create a point-to-site VPN connection for the web app).

    -   Create an NSG and apply it to the virtual network in which the ASE runs (by default the rules included will prevent access from the Internet).

    -   Add a rule to the NSG allowing Internet access to the ports 454-455.

    If you are interested in restricting the *outbound* communication from a web app to a particular service on the Internet, then you need to:

    -   Configure the ASE, virtual network, App Service plan, and web app as above.

    -   Add two outbound rules to the NSG: one that allows access to permitted service and another that denies all outbound Internet.

    For CSLA's situation, inbound access to the e-commerce web app does not need to be restricted, but the outbound communication to the payment gateway does need to be restricted.

    To meet the antivirus requirement, you need only deploy to Azure since that requirement is itself met by Azure and managed against the virtual machines running your web app on your behalf.

    By structuring the web app so all it does it handle the e-commerce transaction, you would meet the server specialization requirement. By capitalizing on web apps you are inherently addressing the patching requirement since Azure handles that for you (with the exception of any custom code or libraries your application may use).

    There is no need to store cardholder data in this scenario, so by having SSL the requirement for protection of data in transit and at rest is also met.

2.  *Would you recommend they use Azure virtual machines? Why or why not?*

    While virtual machines could certainly be used to enable a PCI compliant solution, they would not meet the customer requirement for minimizing infrastructure efforts.

*Data warehouse*

1.  *How would you recommend Contoso implement their data warehouse?*

    They could use Azure SQL Data Warehouse.

2.  *How would Contoso schedule nightly data transfers from their OLTP database to their data warehouse?*

    They would need to provision an instance of Azure Data Factory, and then utilize the Azure Data Factory Copy Wizard to setup a recurring copy from their SQL Database instance to existing tables in their SQL Data Warehouse. They could enable PolyBase in the Copy Wizard to speed up the copying process.

## Checklist of preferred objection handling

*It is not clear to us from the Azure Trust Center just how Azure helps our solution become PCI compliant.*

The Azure Trust Center helps you understand what Azure services have been certified for PCI compliance (for example, the services with which you could build a PCI compliant solution), but it does not describe how you build a PCI compliant solution on Azure. To fully accomplish a PCI compliant solution, you must address the requirements of PCI according to how you are handling cardholder data and the scope of your services. In many cases, Azure's PCI compliance attestations will be enough to satisfy aspects of PCI compliance for your solution, but there are at minimum some items which you must handle as a part of building your application (for example, it is up to you to define and enforce secure password policies).

*Can we provide a solution that scales to meet our public demand, but is also secure for use by our call center and warehouse?*

Yes. Azure can provide a solution that is both scalable and secure.

*Our PCI compliance requires us to have a quarterly audit and to conduct occasional penetration tests. Is this supported by Azure?*

Yes, with prior approval.

-   Because such testing can be indistinguishable from a real attack, it is critical that customers conduct penetration testing only after obtaining approval in advance from Azure Customer Support. Penetration testing must be conducted in accordance with our terms and conditions. Requests for penetration testing should be submitted with a minimum of 7-day advanced notice.

-   Tests that would cause a Denial of Service (DoS) are prohibited.

-   See [https://security-forms.azure.com/penetration-testing/terms](https://security-forms.azure.com/penetration-testing/terms).

*Can we audit the Azure data center?*
No. Our independent audits and certifications are shared with customers in lieu of individual customer audits. These certifications and attestations accurately represent how we obtain and meet our security and compliance objectives, and serve as a practical mechanism to validate our promises for all customers. Allowing potentially thousands of customers to audit our services would not be a scalable practice and might compromise security and privacy. Our independent third-party validation program includes audits that are conducted on an annual basis to provide verification of Azure security controls.

*In the past, we have relied on SOASTA CloudTest to design and execute our web load tests at scale. In moving to Azure, are we still able to capitalize on CloudTest?*
Yes. Azure is a supported cloud provider for CloudTest, and your applications hosted in Azure can have load and performance tests conducted against them from SOASTA's global network of cloud resources, while monitoring results in their big-data, real-time streaming analytics platform.

*Our previous infrastructure did not have great performance monitoring of our websites. What options would you recommend we investigate that would work with our web apps in Azure?*
Web apps in Azure include first-class support for both Microsoft Application Insights and NewRelic Application Performance Monitoring---both of which enable you to collect performance telemetry from your web apps as they are running. You can view and analyze traces from both server-side and browser-side telemetry, diagnose errors, and set alerts from within the Azure Portal. Contoso can also capitalize on Log Analytics (a feature of Microsoft Operations Management Suite) by having the Application Insights logs or the Web App Diagnostic logs pushed to a Storage Account and then picked up and made searchable using the Custom Log. Alternately, they can also push their New Relic logs into Log Analytics, as well giving them a single pane of glass to do all of their monitoring through Operations Management Suite.

*We have heard that Azure's data warehouse can be paused? Does that mean we have to store all our data in Azure Storage first before we can pause the instances and risk losing our data?*
SQL Data Warehouse uses storage into two ways, and both enable the data to exist even while the SQL DW instance is paused. For data that is managed by SQL Data Warehouse (e.g., it is inserted directly into relational or columnar tables), it is stored in Azure Premium Storage. For data supporting external tables in SQL DW, this data resides in Azure Standard Storage and is referenced via PolyBase, a component of SQL Data Warehouse.

## Customer quote (to be read back to the attendees at the end)

*"I can sleep better at night knowing that our e-commerce solution is scalable to handle our biggest days, doesn't sacrifice our required PCI compliance, and actually lowers our infrastructure burden."*

Francisco Martinez, CEO of Contoso Sports League Association

